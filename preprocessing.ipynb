{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download NLTK data files\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import datasets\n",
    "twitter_train = pd.read_csv('raw data\\\\twitter_training.csv', header=None, names=['Tweet id','topic', 'sentiment','Tweet content'])\n",
    "twitter_val = pd.read_csv('raw data\\\\twitter_validation.csv', header=None, names=['Tweet id','topic', 'sentiment','Tweet content'])\n",
    "twitter = pd.concat([twitter_train, twitter_val], ignore_index=True)\n",
    "emotion_text = pd.read_csv('raw data\\\\tweet_emotions.csv')\n",
    "youtube_comments = pd.read_csv('raw data\\\\YoutubeCommentsDataSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean data (duplicates, missing values, uniform text, etc.)\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "        # Remove user mentions and hashtags\n",
    "        text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "        # Remove punctuation and special characters\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        # Remove numbers\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = [lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words]\n",
    "        \n",
    "        return ' '.join(words)\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop irrelevant rows\n",
    "twitter = twitter[twitter['sentiment'] != 'Irrelevant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map youtube labels\n",
    "capital = {\n",
    "    'positive': 'Positive',\n",
    "    'negative': 'Negative',\n",
    "    'neutral': 'Neutral'\n",
    "}\n",
    "youtube_comments['Sentiment'] = youtube_comments['Sentiment'].map(capital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map emotions to uniform data\n",
    "emotion_to_sentiment = {\n",
    "    'enthusiasm': 'Positive',\n",
    "    'surprise': 'Positive',\n",
    "    'love': 'Positive',\n",
    "    'fun': 'Positive',\n",
    "    'happiness': 'Positive',\n",
    "    'neutral': 'Neutral',\n",
    "    'relief': 'Positive',\n",
    "    'anger': 'Negative',\n",
    "    'boredom': 'Negative',\n",
    "    'hate': 'Negative',\n",
    "    'worry': 'Negative',\n",
    "    'sadness': 'Negative',\n",
    "    'empty': 'Negative'\n",
    "}\n",
    "\n",
    "# Apply mapping to emotion dataset\n",
    "emotion_text['sentiment'] = emotion_text['sentiment'].map(emotion_to_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess data\n",
    "# Twitter dataset\n",
    "twitter['cleaned_text'] = twitter['Tweet content'].apply(clean_text)\n",
    "twitter_subset = twitter[['cleaned_text', 'sentiment']]\n",
    "\n",
    "# YouTube dataset\n",
    "youtube_comments['cleaned_text'] = youtube_comments['Comment'].apply(clean_text)\n",
    "youtube_subset = youtube_comments[['cleaned_text', 'Sentiment']]\n",
    "youtube_subset = youtube_subset.rename(columns={'Sentiment': 'sentiment'})\n",
    "\n",
    "# Emotion dataset\n",
    "emotion_text['cleaned_text'] = emotion_text['content'].apply(clean_text)\n",
    "emotion_subset = emotion_text[['cleaned_text', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat data into one dataset\n",
    "combined_data = pd.concat([twitter_subset, youtube_subset, emotion_subset], ignore_index=True)\n",
    "combined_data = combined_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "combined_data = combined_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode data\n",
    "label_encoder = LabelEncoder()\n",
    "combined_data['sentiment_encoded'] = label_encoder.fit_transform(combined_data['sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment mapping: {'Negative': np.int64(0), 'Neutral': np.int64(1), 'Positive': np.int64(2)}\n"
     ]
    }
   ],
   "source": [
    "# Print the mapping for reference\n",
    "sentiment_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Sentiment mapping:\", sentiment_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data\n",
    "combined_data.to_csv('combined_sentiment_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the label encoder for future use\n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im getting borderland murder</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coming border kill</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im getting borderland kill</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im coming borderland murder</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spent hour making something fun dont know huge...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text sentiment  \\\n",
       "0                       im getting borderland murder  Positive   \n",
       "1                                 coming border kill  Positive   \n",
       "2                         im getting borderland kill  Positive   \n",
       "3                        im coming borderland murder  Positive   \n",
       "6  spent hour making something fun dont know huge...  Positive   \n",
       "\n",
       "   sentiment_encoded  \n",
       "0                  2  \n",
       "1                  2  \n",
       "2                  2  \n",
       "3                  2  \n",
       "6                  2  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
